[
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "What’s New & Updated",
    "section": "",
    "text": "Order By\n      Default\n      \n        Title\n      \n      \n        Date - Oldest\n      \n      \n        Date - Newest\n      \n      \n        Author\n      \n    \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nIs Fortran better than Python for teaching the basics of numerical linear algebra?\n\n\n\nblog\n\n\n\n\n\n\n\n\n\nSep 9, 2025\n\n\nJean-Christophe Loiseau\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "publications.html",
    "href": "publications.html",
    "title": "Publications",
    "section": "",
    "text": "Total citations as of September 2025 from Google Scholar \n\n\nCitations\nh-index\ni-10 index\n\n\n\n\n2229\n20\n26\n\n\n\nList of publications in reversed chronological order (most recent first). For each, a link to the journal version is given along with the corresponding arXiv preprint (if not open access).\nNotes : * corresponding author; GS graduate student advisee; VS visiting scholar.\n\n\nR. A. S. FrantzGS*, C. Mimeau, M. SalihogluGS, J.-Ch. Loiseau, & J.-Ch. Robinet (2025). Bifurcation sequence in the wakes of a sphere and a cube. Journal of Fluid Mechanics, vol. 1018. [PDF] \n\n\n\n\n\n\nJ. L. Callaham*GS, J.-Ch. Loiseau, & S. L. Brunton (2023). Multiscale model reduction for incompressible flows. Journal of Fluid Mechanics, vol. 973. [PDF] \n\n\n\n\n\n\nR. A. S. FrantzGS*, J.-Ch. Loiseau, & J.-Ch. Robinet (2023). Krylov methods for large-scale dynamical systems: applications in fluid dynamics. Applied Mechanics Review, 75(3). [PDF] [arXiv] \n\n\n\n\n\n\nM. A. ElhawayGS, F. Romano, J.-Ch. Loiseau, & A. Dazin* (2023). Machine learning for optimal flow control in an axial compressor. European Physical Journal E., 46(28). [PDF] \n\n\n\n\n\n\nG. Nastro*, J.-Ch. Robinet, J.-Ch. Loiseau, P.-Y. Passaggia, & N. Mazellier (2023). Global stability, sensitivity and passive control of low-Reynolds number flows around NACA 4412 swept wings. Journal of Fluid Mechanics, vol. 957. [PDF] \n\n\n\n\n\n\nO. ChehabGS, A. Défossez, J.-Ch. Loiseau, A. Gramfort, & J.-R. King* (2022). Deep recurrent encoder: an end-to-end network to model magnetoencephalography at scale. Neurons, Behavior, Data Analysis and Theory. [PDF] \n\n\n\n\n\n\nJ. L. CallahamGS*, G. Rigas, J.-Ch. Loiseau, & S. L. Brunton (2022). An empirical mean-field model of symmetry-breaking in a turbulent wake. Science Advances, 8(19). [PDF] \n\n\n\n\n\n\nA. Sansica*, J.-Ch. Loiseau, M. Kanamori, A. Hashimoto, & J.-Ch. Robinet (2022). System identification of two-dimensional transonic buffet. AIAA Journal, 60(5). [PDF] \n\n\n\n\n\n\nJ. L. CallahamGS*, S. L. Brunton, & J.-Ch. Loiseau (2022). On the role of nonlinear correlations in reduced-order modelling. Journal of Fluid Mechanics, vol. 938. [PDF] \n\n\n\n\n\n\nA. A. KaptanogluGS*, B. M. de SilvaGS, U. Fasel, K. KahemanGS, A. J. Goldschmidt, J. CallahamGS, C. B. Delahunt, Z. G. Nicolaou, K. ChampionGS, J.-Ch. Loiseau, J. N. Kutz, & S. L. Brunton (2022). PySINDy: a comprehensive Python package for robust sparse system identification. Journal of Open Source Software, 7(69). [PDF] \n\n\n\n\n\n\nJ. L. CallahamGS*, J.-Ch. Loiseau, G. Rigas, & S. L. Brunton (2021). Nonlinear stochastic modelling with Langevin regression. Proceedings of the Royal Society A, 477:20210092. [PDF] \n\n\n\n\n\n\nM. A. BucciGS*, S. Cherubini, J.-Ch. Loiseau, & J.-Ch. Robinet (2021). Influence of freestream turbulence on the flow over a wall roughness. Physical Review Fluids, vol. 6. [PDF] \n\n\n\n\n\n\nJ.-Ch. Loiseau* (2020). Data-driven modeling of the chaotic thermal convection in an annular thermosyphon. Theoretical and Computational Fluid Dynamics, 34(4). [PDF] \n\n\n\n\n\n\nB. M. de SilvaGS*, K. ChampionGS, M. Quade, J.-Ch. Loiseau, J. N. Kutz, & S. L. Brunton (2020). PySINDy: a Python package for the sparse identification of nonlinear dynamical systems from data. Journal of Open Source Software, 5(49). [PDF] \n\n\n\n\n\n\nY. BenganaGS, J.-Ch. Loiseau, J.-Ch. Robinet, & L. S. Tuckerman* (2019). Bifurcation analysis and frequency prediction in shear-driven cavity flow. Journal of Fluid Mechanics, vol. 875. [PDF] \n\n\n\n\n\n\nS. GhoshGS*, J.-Ch. Loiseau, W.-P. Breugem, & L. Brandt (2019). Modal and non-modal linear stability of Poiseuille flow through a channel with a porous substrate. European Journal of Mechanics - B/Fluids, vol. 75. [PDF] \n\n\n\n\n\n\nF. PicellaGS*, J.-Ch. Loiseau, F. Lusseyran, J.-Ch. Robinet, S. Cherubini, & L. Pastur (2018). Successive bifurcations in a fully three-dimensional open cavity flow. Journal of Fluid Mechanics, vol. 844. [PDF] \n\n\n\n\n\n\nJ.-Ch. Loiseau*, B. R. Noack, & S. L. Brunton (2018). Sparse reduced-order modelling: sensor-based dynamics to full-state estimation. Journal of Fluid Mechanics, vol. 844 [PDF] \n\n\n\n\n\n\nJ.-Ch. Loiseau* and S. L. Brunton (2018). Constrained sparse Galerkin regression. Journal of Fluid Mechanics, vol. 838. [PDF] \n\n\n\n\n\n\nM. A. BucciGS*, D. K. PuckertGS, C. A. AndrianoGS, J.-Ch. Loiseau, S. Cherubini, J.-Ch. Robinet, & U. Rist (2017). Roughness-induced transition by quasi-resonance of a varicose global mode. Journal of Fluid Mechanics, vol. 836. [PDF] \n\n\n\n\n\n\nZ. GeGS*, J.-Ch. Loiseau, O. Tammisola, & L. Brandt (2018). An efficient mass-preserving interface-correction level set/ghost fluid method for droplet suspensions under depletion forces. Journal of Computational Physics, vol. 353. [PDF] \n\n\n\n\n\n\nO. Tammisola, J.-Ch. Loiseau, & L. Brandt (2017). Effect of viscosity ratio on the self-sustained instabilities in planar immiscible jets. Physical Review Fluids, vol. 2. [PDF] \n\n\n\n\n\n\nA. A. BanaeiGS, J.-Ch. Loiseau, I. LashgariGS, & L. Brandt (2017). Numerical simulations of elastic capsules with nucleus in shear flow. European Journal of Computational Mechanics, vol. 26. [PDF] \n\n\n\n\n\n\nJ.-Ch. Loiseau*, J.-Ch. Robinet, & E. Leriche (2016). Intermittency and transition to chaos in the cubical lid-driven cavity flow. Fluid Dynamics Research, vol. 48. [PDF] \n\n\n\n\n\n\nA. Ducoin*, J.-Ch. Loiseau, & J.-Ch. Robinet (2016). Numerical investigation of the interaction between laminar to turbulent transition and the wake of an airfoil. European Journal of Mechanics - B/Fluids, vol. 57. [PDF] \n\n\n\n\n\n\nJ. FanonGS, J.-Ch. Loiseau, P. Valluri, I. Bethune, & L. O Naraigh (2016). High-performance computational fluid dynamics: a custom-code approach. European Journal of Physics, vol. 37. [PDF] \n\n\n\n\n\n\nJ.-Ch. Loiseau*, J.-Ch. Robinet, S. Cherubini, & E. Leriche (2014). Investigation of the roughness-induced transition: global stability analyses and direct numerical simulations. Journal of Fluid Mechanics, vol. 760. [PDF]"
  },
  {
    "objectID": "publications.html#selected-work",
    "href": "publications.html#selected-work",
    "title": "Publications",
    "section": "Selected Work",
    "text": "Selected Work\nEinstein, A., Podolsky, B., & Rosen, N. (1935). Can quantum-mechanical description of physical reality be considered complete?. Physical review, 47(10), 777. [pdf] [code and data]   \n\n\n\n\n\n\nEinstein, A. (1965). Concerning an heuristic point of view toward the emission and transformation of light. American Journal of Physics, 33(5), 367. [pdf]"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "Order By\n      Default\n      \n      \n      \n        Title\n      \n      \n        Team\n      \n      \n        Funder\n      \n      \n        Description\n      \n      \n        Start\n      \n      \n        End\n      \n      \n        Funding\n      \n    \n  \n    \n      \n      \n    \n\n\n\n\n\n\n \n\n\n\nTitle\n\n\n\nTeam\n\n\n\nFunder\n\n\n\nDescription\n\n\n\nFunding\n\n\n\nStart\n\n\n\nEnd\n\n\n\n\n\n\n\n\n\n\n\nExploring \n\n\nAcademic Website\n\n\nFunder\n\n\nThe goal of this project is to investigate .\n\n\n$0\n\n\n2024\n\n\n2025\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/news-title/index.html",
    "href": "posts/news-title/index.html",
    "title": "Migrating from Jekyll & AcademicPages to Quarto",
    "section": "",
    "text": "About the news"
  },
  {
    "objectID": "posts/news-title/index.html#summary",
    "href": "posts/news-title/index.html#summary",
    "title": "Migrating from Jekyll & AcademicPages to Quarto",
    "section": "",
    "text": "About the news"
  },
  {
    "objectID": "posts/paper-title/index.html#abstract",
    "href": "posts/paper-title/index.html#abstract",
    "title": "Can quantum-mechanical description of physical reality be considered complete?",
    "section": "Abstract",
    "text": "Abstract\nIn a complete theory there is an element corresponding to each element of reality. A sufficient condition for the reality of a physical quantity is the possibility of predicting it with certainty, without disturbing the system. In quantum mechanics in the case of two physical quantities described by non-commuting operators, the knowledge of one precludes the knowledge of the other. Then either (1) the description of reality given by the wave function in quantum mechanics is not complete or (2) these two quantities cannot have simultaneous reality. Consideration of the problem of making predictions concerning a system on the basis of measurements made on another system that had previously interacted with it leads to the result that if (1) is false then (2) is also false. One is thus led to conclude that the description of reality as given by a wave function is not complete."
  },
  {
    "objectID": "posts/paper-title/index.html#links",
    "href": "posts/paper-title/index.html#links",
    "title": "Can quantum-mechanical description of physical reality be considered complete?",
    "section": "Links",
    "text": "Links\nPublished paper"
  },
  {
    "objectID": "teaching.html",
    "href": "teaching.html",
    "title": "Teaching",
    "section": "",
    "text": "Program\nPeriod\nLanguage\n\n\n\n\nInternational Master Program Factory of the Future\nFall\nEnglish\n\n\n\nDescription –\nPre-requisites –\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProgram\nPeriod\nLanguage\n\n\n\n\nInternational Master Program Factory of the Future\nFall\nEnglish\n\n\n\nDescription –\nPre-requisites –\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProgram\nPeriod\nLanguage\n\n\n\n\nInternational Master Program Factory of the Future\nFall\nEnglish\n\n\n\nDescription –\nPre-requisites –\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProgram\nPeriod\nLanguage\n\n\n\n\nMaster 2 MFFA\nFall\nEnglish\n\n\n\nDescription –\nPre-requisites –\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProgram\nPeriod\nLanguage\n\n\n\n\nProgramme Ingénieur de Spécialité\nSpring\nFrench\n\n\n\nDescription –\nPre-requisites –"
  },
  {
    "objectID": "teaching.html#class-1",
    "href": "teaching.html#class-1",
    "title": "Teaching",
    "section": "",
    "text": "Fall 2024,   Fall 2023\nClass 1 introduction."
  },
  {
    "objectID": "teaching.html#class-2",
    "href": "teaching.html#class-2",
    "title": "Teaching",
    "section": "Class 2",
    "text": "Class 2\n\n\n\n\n\nSpring 2025,   Fall 2023\nClass 2 introduction."
  },
  {
    "objectID": "teaching.html#class-3",
    "href": "teaching.html#class-3",
    "title": "Teaching",
    "section": "Class 3",
    "text": "Class 3\n\n\n\n\n\nSpring 2025,   Spring 2024\nClass 3 introduction."
  },
  {
    "objectID": "contact.html",
    "href": "contact.html",
    "title": "Contact",
    "section": "",
    "text": "Dr. Jean-Christophe Loiseau\nLaboratoire DynFluid\nEcole Nationale Supérieure d’Arts et Métiers\nAddress: 151 boulevard de l’hôpital, 75013 Paris, France\nE-mail: jean-christophe.loiseau at ensam dot eu"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Jean-Christophe Loiseau, PhD",
    "section": "",
    "text": "E-mail\n  \n  \n    \n     GitHub\n  \n  \n    \n     LinkedIn\n  \n  \n      ORCID\n  \n  \n      Google Scholar\n  \n  \n      Research Gate\n  \n\n  \n  \n\n\n\n\n\n\nWarning\n\n\n\nSite still under construction. Bare with me.\n\n\n\n\nI’m an Assitant Professor of applied mathematics and fluid dynamics at Arts et Métiers Institute of Technology (Paris, France). I split my time between teaching to (mechanical) engineering students and doing research on topics such as transition to turbulence, flow control and data-driven modelling.\nOn this site I keep a list of my publications, the courses I teach, the open-source softwares I develop or contribute to, as well as a technical blog.\n\n\n\n PySINDy – Sparse identification of nonlinear dynamical systems from data.\n LightKrylov – Implementation of Krylov methods in modern Fortran.\n LightConvex – Convex programming in modern Fortran.\n stdlib – Community-driven development of a standard library for Fortran."
  },
  {
    "objectID": "index.html#experience",
    "href": "index.html#experience",
    "title": "Jean-Christophe Loiseau, PhD",
    "section": "",
    "text": "Researcher, Univerisity"
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Jean-Christophe Loiseau, PhD",
    "section": "",
    "text": "PhD, Univerisity"
  },
  {
    "objectID": "index.html#recent-posts",
    "href": "index.html#recent-posts",
    "title": "Jean-Christophe Loiseau, PhD",
    "section": "Recent Posts",
    "text": "Recent Posts\nCheck out the latest  Papers ,  News ,  Events , and  More »\n\n\n\n\n\n\n\n\n\n\nIs Fortran better than Python for teaching the basics of numerical linear algebra?\n\n\n\nSep 9, 2025\n\n\n\n\n\n\nNo matching items\n\n\nAll Posts »"
  },
  {
    "objectID": "people.html",
    "href": "people.html",
    "title": "People",
    "section": "",
    "text": "Postdoc\n\n\n\n\n\n\n\n\n\n\n\n\n\nP.I.\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "people.html#team",
    "href": "people.html#team",
    "title": "People",
    "section": "",
    "text": "Postdoc\n\n\n\n\n\n\n\n\n\n\n\n\n\nP.I.\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "people.html#alumni",
    "href": "people.html#alumni",
    "title": "People",
    "section": "Alumni",
    "text": "Alumni\n\n\n   \n    \n    \n      Order By\n      Default\n      \n      \n      \n        Name\n      \n      \n        Role\n      \n      \n        Started\n      \n      \n        Ended\n      \n    \n  \n    \n      \n      \n    \n\n\n\n\n\n\n \n\n\n\nName\n\n\n\nRole\n\n\n\nStarted\n\n\n\nEnded\n\n\n\n\n\n\n\n\n\n\n\nMohamed Elhawary\n\n\nPhD Alumni\n\n\n2024\n\n\n2021\n\n\n\n\n\n\n\n\n\nRicardo Schuh Frantz\n\n\nPhD Alumni\n\n\n2019\n\n\n2022\n\n\n\n\n\n\n\n\n\nCosimo Tarcia Morisco\n\n\nPhD Alumni\n\n\n2020\n\n\n2016\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#bio",
    "href": "index.html#bio",
    "title": "Jean-Christophe Loiseau, PhD",
    "section": "",
    "text": "I’m an Assitant Professor of applied mathematics and fluid dynamics at Arts et Métiers Institute of Technology (Paris, France). I split my time between teaching to (mechanical) engineering students and doing research on topics such as transition to turbulence, flow control and data-driven modelling.\nOn this site I keep a list of my publications, the courses I teach, the open-source softwares I develop or contribute to, as well as a technical blog."
  },
  {
    "objectID": "posts/blog-title/index.html",
    "href": "posts/blog-title/index.html",
    "title": "Blog posts",
    "section": "",
    "text": "About the blog"
  },
  {
    "objectID": "posts/blog-title/index.html#summary",
    "href": "posts/blog-title/index.html#summary",
    "title": "Blog posts",
    "section": "",
    "text": "About the blog"
  },
  {
    "objectID": "posts/paper-title/einstein.html#abstract",
    "href": "posts/paper-title/einstein.html#abstract",
    "title": "Can quantum-mechanical description of physical reality be considered complete?",
    "section": "Abstract",
    "text": "Abstract\nIn a complete theory there is an element corresponding to each element of reality. A sufficient condition for the reality of a physical quantity is the possibility of predicting it with certainty, without disturbing the system. In quantum mechanics in the case of two physical quantities described by non-commuting operators, the knowledge of one precludes the knowledge of the other. Then either (1) the description of reality given by the wave function in quantum mechanics is not complete or (2) these two quantities cannot have simultaneous reality. Consideration of the problem of making predictions concerning a system on the basis of measurements made on another system that had previously interacted with it leads to the result that if (1) is false then (2) is also false. One is thus led to conclude that the description of reality as given by a wave function is not complete."
  },
  {
    "objectID": "posts/paper-title/einstein.html#links",
    "href": "posts/paper-title/einstein.html#links",
    "title": "Can quantum-mechanical description of physical reality be considered complete?",
    "section": "Links",
    "text": "Links\nPublished paper"
  },
  {
    "objectID": "posts/paper-title/test.html#abstract",
    "href": "posts/paper-title/test.html#abstract",
    "title": "This is a test?",
    "section": "Abstract",
    "text": "Abstract\nIn a complete theory there is an element corresponding to each element of reality. A sufficient condition for the reality of a physical quantity is the possibility of predicting it with certainty, without disturbing the system. In quantum mechanics in the case of two physical quantities described by non-commuting operators, the knowledge of one precludes the knowledge of the other. Then either (1) the description of reality given by the wave function in quantum mechanics is not complete or (2) these two quantities cannot have simultaneous reality. Consideration of the problem of making predictions concerning a system on the basis of measurements made on another system that had previously interacted with it leads to the result that if (1) is false then (2) is also false. One is thus led to conclude that the description of reality as given by a wave function is not complete."
  },
  {
    "objectID": "posts/paper-title/test.html#links",
    "href": "posts/paper-title/test.html#links",
    "title": "This is a test?",
    "section": "Links",
    "text": "Links\nPublished paper"
  },
  {
    "objectID": "teaching.html#mathematics-for-engineers",
    "href": "teaching.html#mathematics-for-engineers",
    "title": "Teaching",
    "section": "",
    "text": "Fall 2024,   Fall 2023\nClass 1 introduction."
  },
  {
    "objectID": "teaching.html#introduction-to-control-theory",
    "href": "teaching.html#introduction-to-control-theory",
    "title": "Teaching",
    "section": "Introduction to control theory",
    "text": "Introduction to control theory\n\n\n\n\n\nSpring 2025,   Fall 2023\nClass 2 introduction."
  },
  {
    "objectID": "teaching.html#arts-et-métiers",
    "href": "teaching.html#arts-et-métiers",
    "title": "Teaching",
    "section": "",
    "text": "Program\nPeriod\nLanguage\n\n\n\n\nInternational Master Program Factory of the Future\nFall\nEnglish\n\n\n\nDescription –\nPre-requisites –\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProgram\nPeriod\nLanguage\n\n\n\n\nInternational Master Program Factory of the Future\nFall\nEnglish\n\n\n\nDescription –\nPre-requisites –\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProgram\nPeriod\nLanguage\n\n\n\n\nInternational Master Program Factory of the Future\nFall\nEnglish\n\n\n\nDescription –\nPre-requisites –\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProgram\nPeriod\nLanguage\n\n\n\n\nMaster 2 MFFA\nFall\nEnglish\n\n\n\nDescription –\nPre-requisites –\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProgram\nPeriod\nLanguage\n\n\n\n\nProgramme Ingénieur de Spécialité\nSpring\nFrench\n\n\n\nDescription –\nPre-requisites –"
  },
  {
    "objectID": "teaching.html#université-de-la-rochelle",
    "href": "teaching.html#université-de-la-rochelle",
    "title": "Teaching",
    "section": "Université de La Rochelle",
    "text": "Université de La Rochelle\n\nPhysics Informed Neural Networks and System Identification\n\n\n\n\n\n\n\n\n\nProgram\nPeriod\nLanguage\n\n\n\n\nMaster 2 MIX\nFall\nFrench\n\n\n\nDescription –\nPre-requisites –"
  },
  {
    "objectID": "teaching.html#sorbonne-université",
    "href": "teaching.html#sorbonne-université",
    "title": "Teaching",
    "section": "Sorbonne Université",
    "text": "Sorbonne Université\n\nIntroduction to Machine Learning\n\n\n\n\n\n\n\n\n\nProgram\nPeriod\nLanguage\n\n\n\n\nMaster 2 MFFA\nFall\nFrench\n\n\n\nDescription –\nPre-requisites –"
  },
  {
    "objectID": "index.html#selected-projects",
    "href": "index.html#selected-projects",
    "title": "Jean-Christophe Loiseau, PhD",
    "section": "",
    "text": "PySINDy – Sparse identification of nonlinear dynamical systems from data.\n LightKrylov – Implementation of Krylov methods in modern Fortran.\n LightConvex – Convex programming in modern Fortran.\n stdlib – Community-driven development of a standard library for Fortran."
  },
  {
    "objectID": "posts/blog-title/fortran_vs_python.html",
    "href": "posts/blog-title/fortran_vs_python.html",
    "title": "Is Fortran better than Python for teaching the basics of numerical linear algebra?",
    "section": "",
    "text": "Disclaimer – This is not a post about which language is the most elegant or which implementation is the fastest (we all know it’s Fortran). It’s about teaching the basics of scientific computing to engineering students with a limited programming experience. Yes, the Numpy/Scipy/matplotlib stack is awesome. Yes, you can use numba or jax to speed up your code, or Cython, or even Mojo the latest kid in the block. Or you know what? Use Julia or Rust instead. But that’s not the basics and it’s beyond the point.\nI’ve been teaching an Intro to Scientific Computing class for nearly 10+ years. This class is intended for second year engineering students and, as such, places a large emphasis on numerical linear algebra. Like the rest of Academia, I’m using a combination of Python and numpy arrays for this. Yet, after all these years, I start to believe it ain’t necessarily the right choice for a first encounter with numerical linear algebra. Obvisouly everything is not black and white and I’ll try to be nuanced. But, in my opinion, a strongly typed language such as Fortran might lead to an overall better learning experience. And that’s what it’s all about when you start Uni: learning the principles of scientific programming, not the quirks of a particular language (unless you’re a CS student, which is a different crowd).\nDon’t get me wrong though. Being proficient with numpy, scipy and matplotlib is an absolute necessity for STEM students today, and that’s a good thing. Even from an educational perspective, the scientific Python ecosystem enables students to do really cool projects, putting the fun back in learning. It would be completely non-sensical to deny this. But using x = np.linalg.solve(A, b) ain’t the same thing as having a basic understanding of how these algorithms work. And to be clear: the goal of these classes is not to transform a student into a numerical linear algebra expert who could write the next generation LAPACK. It is to teach them just enough of numerical computing so that, when they’ll transition to an engineering position, they’ll be able to make an informed decision regarding which solver or algorithm to use when writing a simulation or data analysis tool to tackle whatever business problem they’re working on.\nIf you liked and aced your numerical methods class, then what I’ll discuss might not necessary be relatable. You’re one of a kind. More often than not, students struggle with such courses. This could be due to genuine comprehension difficulties, or lazyness and lack of motivation simply because they don’t see the point. While both issues are equally important to address, I’ll focus on the first one: students who are willing to put the effort into learning the subject but have difficulties transforming the mathematical algorithm into an actionnable piece of code. Note however that initially motivated but struggling students might easily drift to the second type, hence my focus there first.\nIn the rest of this post, I’ll go through two examples. For each, I’ll show a typical Python code such a student might write and discuss all of the classical problems they’ve encountered to get there. A large part of these are syntax issues or result from the permissiveness of an interpreted language like Python which is a double edged sword. Then I’ll show an equivalent Fortran implementation and explain why I believe it can solve part of these problems. But first, I need to address the two elephants in the room:\nWith that being said, let’s get started with a concrete, yet classical, example to illustrate my point."
  },
  {
    "objectID": "posts/blog-title/fortran_vs_python.html#the-hello-world-of-iterative-solvers",
    "href": "posts/blog-title/fortran_vs_python.html#the-hello-world-of-iterative-solvers",
    "title": "Is Fortran better than Python for teaching the basics of numerical linear algebra?",
    "section": "The Hello World of iterative solvers",
    "text": "The Hello World of iterative solvers\nYou’ve started University a year ago and are taking your first class on scientific computing. Maybe you already went through the hassle of Gaussian elimination and the LU factorization. During the last class, Professor X discussed about iterative solvers for linear systems. It is now the hands-on session and today’s goal is to implement the Jacobi method. Why Jacobi? Because it is simple enough to implement in an hour or so.\nThe exact problem you’re given is the following:\n\nConsider the Poisson equation with homogeneous Dirichlet boundary conditions on the unit-square. Assume the Laplace operator has been discretized using a second-order accurate central finite-difference scheme. The discretized equation reads \\[\\dfrac{u_{i+1, j} - 2u_{i, j} + u_{i-1, j}}{\\Delta x^2} + \\dfrac{u_{i, j+1} - 2u_{i, j} + u_{i, j-1}}{\\Delta y^2} = b_{i, j}.\\] For the sake of simplicity, take \\(\\Delta x = \\Delta y\\). Write a function implementing the Jacobi method to solve the resulting linear system to a user-prescribed tolerance.\n\nWe can all agree this is a simple enough yet somewhat realistic example. More importantly, it is sufficient to illustrate my point. Here is what the average student might write in Python.\nimport numpy as np\n\ndef jacobi(b , dx, tol, maxiter):\n    # Initialize variables.\n    nx, ny = b.shape\n    residual = 1.0\n    u = np.zeros((nx, ny))\n    tmp = np.zeros((nx, ny))\n\n    # Jacobi solver.\n    for iteration in range(maxiter):\n        # Jacobi iteration.\n        for i in range(1, nx-1):\n            for j in range(1, ny-1):\n                tmp[i, j] = 0.25*(b[i, j]*dx**2 - u[i+1, j] - u[i-1, j] \n                                                - u[i, j+1] - u[i, j-1])\n\n        # Compute residual\n        residual = np.linalg.norm(u-tmp)\n        # Update solution.\n        u = tmp\n        # If converged, exit the loop.\n        if residual &lt;= tol:\n            break\n\n    return u\nYes, you shouldn’t do for loops in Python. But remember, you are not a seasoned programmer. You’re taking your first class on scientific computing and that’s how the Jacobi method is typically presented. Be forgiving.\n\nWhere do students struggle?\nAdmittidely, the code is quite readable and look very similar to the pseudocode you’d use to describe the Jacobi method. But if you’re reading this blog post, there probably are a handful of things you’ve internalized and don’t even think about anymore (true for both Python and Fortran). And that’s precisely what the students (at least mine) struggle with, starting with the very first line.\nWhat the hell is numpy and why do I need it? Also, why import it as np? – These questions come back every year. Yet, I don’t have satisfying answers. I always hesitate between\n\nTrust me kid, you don’t want to use nested lists in Python to do any serious numerical computing.\n\nwhich naturally begs the question of why, or\n\nWhen I said we’ll use Python for this scientific computing class, what I really meant is we’ll use numpy which is a package written for numerical computing because Python doesn’t naturally have good capabilities for number crunching. As for the import as np, that’s just a convention.\n\nAnd this naturally leads to the question of “why Python in the first place then?” for which the only valid answer I have is\n\nWell, because Python is supposed to be easy to learn and everybody uses it.\n\nClearly, import numpy as np is an innocent-looking line of code. It has nothing to do with the subject being taught though, and everything with the choice of the language, only diverting the students from the learning process.\nI coded everything correctly, 100% sure, but I get this weird error message about indentation – Oh boy! What a classic! The error message varies between\nIndentationError: expected an indented block\nand\nTabError: inconsistent use of tabs and spaces in indentation\n&lt;TAB&gt; versus SPACE is a surprisingly hot topic in programming which I don’t want to engage in. A seasoned programmer might say “simply configure your IDE properly” which is fair. But we’re talking about your average student (who’s not a CS one remember) and they might use IDLE or even just notepad. As for the IndentationError, it is a relatively easy error to catch. Yet, the fact that for, if or while constructs are not clearly delineated in Python other than visually is surprisingly hard for students. I find that it puts an additional cognitive burden on top of a subject which is already demanding enough.\nIt could also be more subtle. The code might run but the results are garbage because the student wrote something like\n    for iteration in range(maxiter):\n    # Jacobi iteration.\n    for i in range(1, nx-1):\n    for j in range(1, ny-1):\n    tmp[i, j] = 0.25*(b[i, j]*dx**2 - u[i+1, j] - u[i-1, j] \n                                                - u[i, j+1] - u[i, j-1])\nYou might argue that this perfectly understandable, though if you want to be picky, there is no dealineation of where the different loops end. Which the whole point of indentation in Python. But students do not necessarily get that.\nWhy range(1, nx-1) and not range(2, nx-1)? The first column/row is my boundary. – Another classic related to 0-based vs 1-based indexing. And another very hot debate I don’t want to engage in. The fact however is that linear algebra (and a lot of scientific computing for that matter) use 1-based indexing. Think about vectors or matrices. Almost every single maths books write them as\n\\[\n\\begin{bmatrix}\n    a_{11} & a_{12} & a_{13} \\\\\n    a_{21} & a_{22} & a_{23} \\\\\n    a_{31} & a_{32} & a_{33}\n\\end{bmatrix}.\n\\]\nThe upper left element has the (1, 1) index, not (0, 0). Why use a language with 0-based indexing for linear algebra other than putting an additional cognitive burden on the students learning the subject? This is a recipe for the nefarious off-by-one error. And these errors are sneaky. The code might run but produce incorrect results and it’s a nightmare for the students (or the poor TA helping them) to figure out why.\nWhy np.linalg.norm and not just norm or np.norm? – This is one is related to my first point. When you’re used to it, you no longer question it. But you don’t know students then and, once more, I don’t have a really clear answer other than\n\nWell, linalg stand for linear algebra, and np.linalg is a collection of linear algebra related function. It is a submodule of numpy, the package I told you about before.\n\nGrouping like-minded functionalities into a dedicated submodule is definitely good practice, no question there. Discussing the architecture of numpy makes a lot of sense when students have to do a big project involving numerical computing but not strictly speaking about numerical computing. On the other hand, when it is their first numerical computing class (and possibly first with Python) I find it distracting. Again, it’s not a big thing really but still. And then you have to explain why np.det and np.trace are not part of np.linalg…\nOther common problems – There are other very common problems like using the wrong function or inconsistent use of lower- or upper-case for variables. Once you know Python is case-sensitive, this is mainly a concentration problem. No big deal there. But there is one last thing that tends to cause problems to distracted students and that has to do with the dynamic nature of Python. Nowhere in the code snippet is it clearly specified that b needs to be a two-dimensional np.array of real numbers nor that it shouldn’t be modified by the function. It is only implicit. And that can be a big problem for students when working with marginally more complicated algorithms. Sure enough, type annotation is a thing now in Python, but it still is pretty new and comparatively few people actually use them.\n\n\nWhat about Fortran?\nAlright, I’ve spent the last five minutes talking shit about Python but how does Fortran compare with it? Here is a typical implementation of the same function. I’ve actually digged it from my own set of archived homeworks I did 15+ years ago and hardly modified it.\nfunction jacobi(b, dx, tol, maxiter) result(u)\n    implicit none\n    real, dimension(:, :), intent(in) :: b\n    real, intent(in) :: dx, tol\n    integer, intent(in) :: maxiter\n    real, dimension(:, :), allocatable :: u\n    ! Internal variables.\n    real, dimension(:, :), allocatable :: tmp\n    integer :: nx, ny, i, j, iteration\n\n    ! Initialize variables.\n    nx = size(b, 1) ; ny = size(b, 2)\n    allocate(u(nx, ny), source = 0.0)\n    residual = 1.0\n\n    ! Jacobi solver.\n    do iteration = 1, maxiter\n        ! Jacobi iteration.\n        do j = 2, ny-1\n            do i = 2, nx-1\n                tmp(i, j) = 0.25*(b(i, j)*dx**2 - u(i+1, j) - u(i-1, j) &\n                                                - u(i, j+1) - u(i, j-1))\n            enddo\n        enddo\n\n        ! Compute residual.\n        residual = norm2(u - tmp)\n        ! Update solution.\n        u = tmp\n        ! If convered, exit the loop.\n        if (residual &lt;= tol) exit\n    enddo\n\nend function\nNo surprise there. The task is sufficiently simple that both implementations are equally readable. If anything, the Fortran one is a bit more verbose. But in view of what I’ve just said about the Python code, I think it actually a good thing. Let me explain.\nDefinition of the variables – Fortran is a strongly typed language. Lines 2 to 8 are nothing but the definitions of the different variables used in the routine. While you might argue it’s a pain in the a** to write these, I think it can actually be very beneficial for students. Before even implementing the method, they have to clearly think about which variables are input, which are ouput, what are their types and dimensions. And to do so, they have to have at least a minimal understanding of the algorithm itself. Once it’s done, there are no more surprises (hopefully), and the contract between the code and the user is crystal clear. And more importantly, the effort put in clearly identifying the input and output of numerical algorithm usually pays off and leads to less error-prone process.\nBegining and end of the constructs – Fortran uses the do/end do (or enddo) construct, clearly specifying where the loop starts where it ends. The indentation used in the code snippet really is just a matter of style. In constrast to Python, writing\n    do j = 2, ny-1\n    do i = 2, nx-1\n    tmp(i, j) = 0.25*(b(i, j)*dx**2 - u(i+1, j) - u(i-1, j) &\n                                    - u(i, j+1) - u(i, j-1))\n    enddo\n    enddo\ndoes not make the code any less readable and wouldn’t change a dime in terms of computations. It’s a minor thing, fair enough. But it instantly get rid of the IndentationError or TabError which are puzzling students. I may be wrong, but I believe it actually reduces the cognitive load associated with the programming language and let the students focus on the actual numerical linear algebra task.\nNo off-by-one error – By default, Fortran uses a 1-based indexing. No off-by-one errors, period.\nIntrinsic functions for basic scientific computations – While you have to use np.linalg.norm in Python to compute the norm of a vector, Fortran natively has the norm2 function for that. No external library required. If you want to be picky, you may say that norm2 is a weird name and that norm might be just fine.\nSome quirks of Fortran – All is not perfect though, starting with Line 2 and the implicit none statement. This is a historical remnant which is considered good practice by modern Fortran standards but not actually needed. Students being students, they will more likely than not ask questions about it although it has nothing to do with the subject of the class itself. Admittidely, it can be a bit cumbersome to explicitely define all the integers you use even if it’s just for a one-time loop. Likewise, there is the question of real vs double precision vs real(wp) (where wp is yet another variable you’ve defined somewhere). I don’t think it matters too much though when learning the basics of numerical linear algebra algorithms, although it certainly does when you start discussing about precision and performances."
  },
  {
    "objectID": "posts/blog-title/fortran_vs_python.html#linear-least-squares-your-first-step-into-machine-learning",
    "href": "posts/blog-title/fortran_vs_python.html#linear-least-squares-your-first-step-into-machine-learning",
    "title": "Is Fortran better than Python for teaching the basics of numerical linear algebra?",
    "section": "Linear least-squares, your first step into Machine Learning",
    "text": "Linear least-squares, your first step into Machine Learning\nAlright, let’s look at another example. Same class, later in the semester. Professor X now discusses over-determined linear systems and how it relates to least-squares, regression and basic machine learning applications. During the hands-on session, you’re given the following problem\n\nConsider the following unconstrained quadratic program \\[\\mathrm{minimize} \\quad \\| Ax - b \\|_2^2.\\] Write a least-squares solver based on the QR factorization of the matrix \\(A\\). You can safely assume that \\(A\\) is a tall matrix (i.e. \\(m &gt; n\\)).\n\nHere is what the typical Python code written by the students might look like.\nimport numpy as np\n\ndef qr(A):\n    # Initialize variables.\n    m, n = A.shape\n    Q = np.zeros((m, n))\n    R = np.zeros((n, n))\n\n    # QR factorization based on the Gram-Schmidt orthogonalization process.\n    for i in range(n):\n        q = A[:, i]\n        # Orthogonalization w.r.t. to the previous basis vectors.\n        for j in range(i):\n            R[j, i] = np.vdot(q, Q[:, j])\n            q = q - R[j, i]*Q[:, j]\n\n        # Normalize and store the new vector.\n        R[i, i] = np.linalg.norm(q)\n        Q[:, i] = q / R[i, i]\n\n    return Q, R\n\ndef upper_triangular_solve(R, b):\n    # Initialize variables.\n    n = R.shape[0]\n    x = np.zeros((n))\n\n    # Backsubstitution.\n    for i in range(n-1, -1, -1):\n        x[i] = b[i]\n        for j in range(n-1, i, -1):\n            x[i] = x[i] - R[i, j]*x[j]\n        x[i] = x[i] / R[i, i]\n\n    return x\n\ndef lstsq(A, b):\n    # QR factorization.\n    Q, R = qr(A)\n    # Solve R @ x = Q.T @ b.\n    x = upper_triangular_solve(R, Q.T @ b)\n    return x\nThis one was adapted from an exercise I gave last year. In reality, students lumped everything into one big function unless told otherwise, but nevermind. For comparison, here is the equivalent Fortran code.\nsubroutine qr(A, Q, R)\n    implicit none\n    real, dimension(:, :), intent(in) :: A\n    real, dimension(:, :), allocatable, intent(out) :: Q, R\n    ! Internal variables.\n    integer :: i, j, m, n\n    real, dimension(:), allocatable :: q_hat\n\n    ! Initialize variables.\n    m = size(A, 1); n = size(A, 2)\n    allocate(Q(m, n), source=0.0)\n    allocate(R(n, n), source=0.0)\n    \n    ! QR factorization based on the Gram-Schmidt orthogonalization process.\n    do i = 1, n\n        q_hat = A(:, i)\n        ! Orthogonalize w.r.t. the previous basis vectors.\n        do j = 1, i-1\n            R(j, i) = dot_product(q_hat, Q(:, j))\n            q_hat = q_hat - R(j, i)*Q(:, j)\n        end do\n\n        ! Normalize and store the new vector.\n        R(i, i) = norm2(q_hat)\n        Q(:, i) = q_hat / R(i, i)\n    end do\nend subroutine\n\nfunction upper_triangular_solve(R, b) result(x)\n    implicit none\n    real, dimension(:, :), intent(in) :: R\n    real, dimension(:), intent(in) :: b\n    real, dimension(:), allocatable :: x\n    ! Internal variables.\n    integer :: n, i, j\n\n    ! Initialize variables.\n    n = size(R, 1)\n    allocate(x(n), source=0.0)\n\n    ! Backsubstitution.\n    do i = n, 1, -1\n        x(i) = b(i)\n        do j = n-1, i, -1\n            x(i) = x(i) - R(i, j)*x(j)\n        enddo\n        x(i) = x(i) / R(i, i)\n    end do\nend function\n\nfunction lstsq(A, b) result(x)\n    implicit none\n    real, dimension(:, :), intent(in) :: A\n    real, dimension(:), intent(in) :: b\n    real, dimension(:), allocatable :: x\n    ! Internal variables.\n    real, dimension(:, :), allocatable :: Q, R\n\n    ! QR factorization.\n    call qr(A, Q, R)\n    ! Solve R @ x = Q.T @ b.\n    x = upper_triangular_solve(R, matmul(transpose(Q), b))\nend function\nJust like the Jacobi example, both implementations are equally readable. At this point in the semester, the students got somewhat more comfortable with Python. The classical indentation problems were not so much of a problem anymore. The off-by-one errors due to 0-based indexing for the Gram-Schmidt orthogonalization in qr or in the backsubstitution algorithm on the other hand… That was painful. In a 90-minutes class, it took almost a whole hour simply for them to debug these errors.\nBut there was another thing that confused students. A lot. And that has to do with computing dot products in numpy. There’s so many different ways: np.vdot(x, y), np.dot(x.T, y), np.dot(np.transpose(x), y), or x.transpose().dot(y) to list just the ones I have seen in their codes. Again, this has nothing to do with linear algebra, but everything with the language. Not only do they need to learn the math, but they simultaneously need to learn the not-quite-necessarily-math-standard syntax used in the language (yes, I’m looking at you @). It’s just a question of habits, sure enough, but again it can be impeding the learning process.\nOn the other hand, the Fortran implementation is even closer to the standard mathematical description of the algorithm: 1-based indexing, intrinsic dot_product function, etc. But beside the implicit none, there is the need to use a subroutine rather than a function construct for the QR decomposition because it has two output variables. Not a big deal again, but to be fair, it does add another minor layer of abstraction due to the language semantics rather than that of the subject being studied."
  },
  {
    "objectID": "posts/blog-title/fortran_vs_python.html#fortran-may-have-a-slight-edge-but-i-swept-some-things-under-the-rug",
    "href": "posts/blog-title/fortran_vs_python.html#fortran-may-have-a-slight-edge-but-i-swept-some-things-under-the-rug",
    "title": "Is Fortran better than Python for teaching the basics of numerical linear algebra?",
    "section": "Fortran may have a slight edge, but I swept some things under the rug…",
    "text": "Fortran may have a slight edge, but I swept some things under the rug…\nIn the end, when it comes to teaching the basics of numerical linear algebra, Python and Fortran are not that different. And in that regard, neither is Julia which I really like as well. The main advantages I see of using Fortran for this task however are:\n\n1-based indexing : in my experience, the 0-based indexing in Python leads to so many off-by-one erros driving the students crazy. Because linear algebra textbooks naturally use 1-based indexing, having to translate everything in your head to 0-based indices is a huge cognitive burden on top of a subject already demanding enough. You might get used to it eventually, but it’s a painful process impeding the learning outcomes.\nStrong typing : combined with implicit none, having to declare the type, dimension and input or output nature of every variable you use might seem cumbersome at first. But it forces students to pause and ponder to identify which is which. Sure this is an effort, but it is worth it. Learning is not effortless and this effort forces you to have a somewhat better understanding of a numerical algorithm before even starting to implement it. Which I think is a good thing.\nClear delineation of the constructs : at least during the first few weeks, having to rely only on visual clues to identify where does a loop ends in Python seems to be quite complicated for a non-negligible fraction of the students I have. In that respect, the do/enddo construct in Fortran is much more explicit and probably easier to grasp.\n\nObvisouly, I’m not expecting educators worldwide to switch back to Fortran overnight, nor is it necessarily desirable. The advantages I see are non-negligible from my perspective but certainly not enough by themselves. There are many other things that need to be taken into account. Python is a very generalist language. You can do so much more than just numerical computing so it makes complete sense to have it in the classroom. The ecosystem is incredibly vast and the interactive nature definitely has its pros. Notebooks such as Jupyter can be incredible teaching tools (although they come with their own problems in term good coding practices). So are the Pluto notebooks in Julia.\nFortran is good at one thing: enabling computational scientists and engineers to write high-performing mathematical models without all the intricacies of equally peformant but more CS-oriented languages such as C or C++. Sure enough, the modern Fortran ecosystem is orders of magnitude smaller than Python, and targetted toward numerical computing almost exclusively. And the Julia one is fairly impressive. But the community is working on it (see the fortran-lang website or the Fortran discourse if you don’t trust me). The bad rep of Fortran is unjustified, particularly for teaching purposes. Many of its detractors have hardly been exposed to anything else than FORTRAN 77. And it’s true that, by current standards, most of FORTRAN 77 codes are terrible sphagetti codes making extensive use of implicit typing and incomprehensible goto statements. Even I, as a Fortran programmer, acknowledge it. But that’s no longer what Fortran is since the 1990’s, and certainly not today!"
  }
]